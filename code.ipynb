{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\ensemble\\lib\\site-packages\\shap\\utils\\_clustering.py:35: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _pt_shuffle_rec(i, indexes, index_mask, partition_tree, M, pos):\n",
      "c:\\ProgramData\\anaconda3\\envs\\ensemble\\lib\\site-packages\\shap\\utils\\_clustering.py:54: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def delta_minimization_order(all_masks, max_swap_size=100, num_passes=2):\n",
      "c:\\ProgramData\\anaconda3\\envs\\ensemble\\lib\\site-packages\\shap\\utils\\_clustering.py:63: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _reverse_window(order, start, length):\n",
      "c:\\ProgramData\\anaconda3\\envs\\ensemble\\lib\\site-packages\\shap\\utils\\_clustering.py:69: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _reverse_window_score_gain(masks, order, start, length):\n",
      "c:\\ProgramData\\anaconda3\\envs\\ensemble\\lib\\site-packages\\shap\\utils\\_clustering.py:77: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _mask_delta_score(m1, m2):\n",
      "c:\\ProgramData\\anaconda3\\envs\\ensemble\\lib\\site-packages\\shap\\links.py:5: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def identity(x):\n",
      "c:\\ProgramData\\anaconda3\\envs\\ensemble\\lib\\site-packages\\shap\\links.py:10: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _identity_inverse(x):\n",
      "c:\\ProgramData\\anaconda3\\envs\\ensemble\\lib\\site-packages\\shap\\links.py:15: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def logit(x):\n",
      "c:\\ProgramData\\anaconda3\\envs\\ensemble\\lib\\site-packages\\shap\\links.py:20: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _logit_inverse(x):\n",
      "c:\\ProgramData\\anaconda3\\envs\\ensemble\\lib\\site-packages\\shap\\utils\\_masked_model.py:363: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _build_fixed_single_output(averaged_outs, last_outs, outputs, batch_positions, varying_rows, num_varying_rows, link, linearizing_weights):\n",
      "c:\\ProgramData\\anaconda3\\envs\\ensemble\\lib\\site-packages\\shap\\utils\\_masked_model.py:385: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _build_fixed_multi_output(averaged_outs, last_outs, outputs, batch_positions, varying_rows, num_varying_rows, link, linearizing_weights):\n",
      "c:\\ProgramData\\anaconda3\\envs\\ensemble\\lib\\site-packages\\shap\\utils\\_masked_model.py:428: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _init_masks(cluster_matrix, M, indices_row_pos, indptr):\n",
      "c:\\ProgramData\\anaconda3\\envs\\ensemble\\lib\\site-packages\\shap\\utils\\_masked_model.py:439: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _rec_fill_masks(cluster_matrix, indices_row_pos, indptr, indices, M, ind):\n",
      "c:\\ProgramData\\anaconda3\\envs\\ensemble\\lib\\site-packages\\shap\\maskers\\_tabular.py:186: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _single_delta_mask(dind, masked_inputs, last_mask, data, x, noop_code):\n",
      "c:\\ProgramData\\anaconda3\\envs\\ensemble\\lib\\site-packages\\shap\\maskers\\_tabular.py:197: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _delta_masking(masks, x, curr_delta_inds, varying_rows_out,\n",
      "c:\\ProgramData\\anaconda3\\envs\\ensemble\\lib\\site-packages\\shap\\maskers\\_image.py:175: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _jit_build_partition_tree(xmin, xmax, ymin, ymax, zmin, zmax, total_ywidth, total_zwidth, M, clustering, q):\n",
      "c:\\ProgramData\\anaconda3\\envs\\ensemble\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\ProgramData\\anaconda3\\envs\\ensemble\\lib\\site-packages\\shap\\explainers\\_partition.py:676: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def lower_credit(i, value, M, values, clustering):\n",
      "\u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "\u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import io\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# from sklearn.datasets import make_classification\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "# from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "import shap\n",
    "import seaborn as sns\n",
    "# import requests\n",
    "\n",
    "from scripts.check_overlaps import check_overlaps\n",
    "from make_dataset import make_dataset_censored,  make_dataset_uncensored, repeat_masker, COSMIC_CGC_interactions, TF_binding_site_annotations, create_vep_input, read_vcf, long_range_interactions_results, create_vep_input, read_vcf, clean_and_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/dataset_uncensored.csv')\n",
    "df = repeat_masker(df)\n",
    "df = COSMIC_CGC_interactions(df)\n",
    "df = TF_binding_site_annotations(df)\n",
    "df = long_range_interactions_results(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chr</th>\n",
       "      <th>start</th>\n",
       "      <th>ref</th>\n",
       "      <th>alt</th>\n",
       "      <th>id</th>\n",
       "      <th>end</th>\n",
       "      <th>driver</th>\n",
       "      <th>data_source</th>\n",
       "      <th>DNA</th>\n",
       "      <th>LINE</th>\n",
       "      <th>...</th>\n",
       "      <th>known_driver_gene_2kb_downstream</th>\n",
       "      <th>known_driver_gene_2kb_upstream</th>\n",
       "      <th>TF_loss</th>\n",
       "      <th>TF_gain</th>\n",
       "      <th>TF_loss_diff</th>\n",
       "      <th>TF_gain_diff</th>\n",
       "      <th>CTCF_interactions</th>\n",
       "      <th>CTCF_chains</th>\n",
       "      <th>POLR2A_interactions</th>\n",
       "      <th>POLR2A_chains</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1342375</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>mut943</td>\n",
       "      <td>1342375</td>\n",
       "      <td>0</td>\n",
       "      <td>COSMIC</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.461989</td>\n",
       "      <td>4.134149</td>\n",
       "      <td>5.763321</td>\n",
       "      <td>3.928504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2489274</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>mut245</td>\n",
       "      <td>2489274</td>\n",
       "      <td>1</td>\n",
       "      <td>ICGC</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.934233</td>\n",
       "      <td>3.956033</td>\n",
       "      <td>3.028976</td>\n",
       "      <td>1.290733</td>\n",
       "      <td>0.910467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2492155</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>mut244</td>\n",
       "      <td>2492155</td>\n",
       "      <td>1</td>\n",
       "      <td>ICGC</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.379211</td>\n",
       "      <td>4.819892</td>\n",
       "      <td>2.873550</td>\n",
       "      <td>1.947785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>16477460</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>mut124</td>\n",
       "      <td>16477460</td>\n",
       "      <td>1</td>\n",
       "      <td>ICGC</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.877773</td>\n",
       "      <td>5.922046</td>\n",
       "      <td>4.237756</td>\n",
       "      <td>2.917693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>19114389</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>mut976</td>\n",
       "      <td>19114389</td>\n",
       "      <td>0</td>\n",
       "      <td>COSMIC</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.025076</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.691125</td>\n",
       "      <td>0.482339</td>\n",
       "      <td>0.580283</td>\n",
       "      <td>0.338505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>X</td>\n",
       "      <td>142919453</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>mut866</td>\n",
       "      <td>142919453</td>\n",
       "      <td>0</td>\n",
       "      <td>COSMIC</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.124983</td>\n",
       "      <td>0.079273</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>X</td>\n",
       "      <td>145999464</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>mut836</td>\n",
       "      <td>145999464</td>\n",
       "      <td>0</td>\n",
       "      <td>COSMIC</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087</th>\n",
       "      <td>X</td>\n",
       "      <td>148496412</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>mut661</td>\n",
       "      <td>148496412</td>\n",
       "      <td>0</td>\n",
       "      <td>COSMIC</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>X</td>\n",
       "      <td>152710276</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>mut927</td>\n",
       "      <td>152710276</td>\n",
       "      <td>0</td>\n",
       "      <td>COSMIC</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.597337</td>\n",
       "      <td>0.383606</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>X</td>\n",
       "      <td>153006175</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>mut742</td>\n",
       "      <td>153006175</td>\n",
       "      <td>0</td>\n",
       "      <td>COSMIC</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.660844</td>\n",
       "      <td>0.386039</td>\n",
       "      <td>0.235855</td>\n",
       "      <td>0.036544</td>\n",
       "      <td>0.020637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1086 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     chr      start ref alt      id        end  driver data_source  DNA  LINE  \\\n",
       "0      1    1342375   A   G  mut943    1342375       0      COSMIC    0     0   \n",
       "1      1    2489274   G   A  mut245    2489274       1        ICGC    0     0   \n",
       "2      1    2492155   T   A  mut244    2492155       1        ICGC    0     0   \n",
       "3      1   16477460   T   C  mut124   16477460       1        ICGC    0     0   \n",
       "4      1   19114389   G   A  mut976   19114389       0      COSMIC    0     0   \n",
       "...   ..        ...  ..  ..     ...        ...     ...         ...  ...   ...   \n",
       "1085   X  142919453   A   G  mut866  142919453       0      COSMIC    0     1   \n",
       "1086   X  145999464   G   T  mut836  145999464       0      COSMIC    0     0   \n",
       "1087   X  148496412   G   T  mut661  148496412       0      COSMIC    0     0   \n",
       "1088   X  152710276   C   T  mut927  152710276       0      COSMIC    0     0   \n",
       "1089   X  153006175   T   G  mut742  153006175       0      COSMIC    0     0   \n",
       "\n",
       "      ...  known_driver_gene_2kb_downstream  known_driver_gene_2kb_upstream  \\\n",
       "0     ...                                 0                               0   \n",
       "1     ...                                 0                               0   \n",
       "2     ...                                 0                               0   \n",
       "3     ...                                 0                               0   \n",
       "4     ...                                 0                               0   \n",
       "...   ...                               ...                             ...   \n",
       "1085  ...                                 0                               0   \n",
       "1086  ...                                 0                               0   \n",
       "1087  ...                                 0                               0   \n",
       "1088  ...                                 0                               0   \n",
       "1089  ...                                 0                               0   \n",
       "\n",
       "      TF_loss  TF_gain  TF_loss_diff  TF_gain_diff  CTCF_interactions  \\\n",
       "0         0.0      0.0      0.000000      0.000000           5.461989   \n",
       "1         0.0      1.0      0.000000      0.934233           3.956033   \n",
       "2         0.0      0.0      0.000000      0.000000           6.379211   \n",
       "3         0.0      0.0      0.000000      0.000000           7.877773   \n",
       "4         2.0      0.0      1.025076      0.000000           0.691125   \n",
       "...       ...      ...           ...           ...                ...   \n",
       "1085      0.0      0.0      0.000000      0.000000           0.124983   \n",
       "1086      0.0      0.0      0.000000      0.000000           0.000158   \n",
       "1087      0.0      0.0      0.000000      0.000000           0.000003   \n",
       "1088      0.0      0.0      0.000000      0.000000           0.597337   \n",
       "1089      0.0      1.0      0.000000      1.660844           0.386039   \n",
       "\n",
       "      CTCF_chains  POLR2A_interactions  POLR2A_chains  \n",
       "0        4.134149             5.763321       3.928504  \n",
       "1        3.028976             1.290733       0.910467  \n",
       "2        4.819892             2.873550       1.947785  \n",
       "3        5.922046             4.237756       2.917693  \n",
       "4        0.482339             0.580283       0.338505  \n",
       "...           ...                  ...            ...  \n",
       "1085     0.079273             0.000006       0.000006  \n",
       "1086     0.000120             0.000013       0.000013  \n",
       "1087     0.000003             0.000000       0.000000  \n",
       "1088     0.383606             0.000019       0.000019  \n",
       "1089     0.235855             0.036544       0.020637  \n",
       "\n",
       "[1086 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the input file for VEP<br>\n",
    "This file is then given to Ensembl VEP <br>\n",
    "We used the web version: https://grch37.ensembl.org/Homo_sapiens/Tools/VEP/<br>\n",
    "Make sure you are using the Grch37 version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_vep_input(df, \"data/VEP/vep_input.vcf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv('data/test_data_final.csv')\n",
    "test_df_vcf = create_vep_input(test_df, \"data/VEP/vep_input_test.vcf\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading VEP output<br>\n",
    "The file generated by Ensembl VEP is downloaded (in .txt format) and used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vep_output = read_vcf('data/VEP/vep_output.txt')\n",
    "df_vep_output_test = read_vcf('data/VEP/vep_output_test.txt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean and preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vep_output = clean_and_preprocess(df_vep_output)\n",
    "df_vep_output_test = clean_and_preprocess(df_vep_output_test)\n",
    "# df_vep_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chr</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>ref</th>\n",
       "      <th>alt</th>\n",
       "      <th>region_type</th>\n",
       "      <th>reg_id</th>\n",
       "      <th>data_source</th>\n",
       "      <th>id</th>\n",
       "      <th>driver</th>\n",
       "      <th>qual</th>\n",
       "      <th>filter</th>\n",
       "      <th>info</th>\n",
       "      <th>format</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>111231125</td>\n",
       "      <td>111231125</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>enhancers.bed</td>\n",
       "      <td>enhancers::chr11:111222000-111233000::NA::NA</td>\n",
       "      <td>Rheinbay et al 2020</td>\n",
       "      <td>test0</td>\n",
       "      <td>1</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>111232885</td>\n",
       "      <td>111232885</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>enhancers.bed</td>\n",
       "      <td>enhancers::chr11:111222000-111233000::NA::NA</td>\n",
       "      <td>Rheinbay et al 2020</td>\n",
       "      <td>test1</td>\n",
       "      <td>1</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>86866372</td>\n",
       "      <td>86866372</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>enhancers.bed</td>\n",
       "      <td>enhancers::chr7:86865600-86866400::NA::NA</td>\n",
       "      <td>Rheinbay et al 2020</td>\n",
       "      <td>test2</td>\n",
       "      <td>1</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2267139</td>\n",
       "      <td>2267139</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>enhancers.bed</td>\n",
       "      <td>enhancers::chr1:2267000-2269600::NA::NA</td>\n",
       "      <td>Rheinbay et al 2020</td>\n",
       "      <td>test3</td>\n",
       "      <td>1</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>111226848</td>\n",
       "      <td>111226848</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>enhancers.bed</td>\n",
       "      <td>enhancers::chr11:111222000-111233000::NA::NA</td>\n",
       "      <td>Rheinbay et al 2020</td>\n",
       "      <td>test4</td>\n",
       "      <td>1</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>9</td>\n",
       "      <td>125026995</td>\n",
       "      <td>125026996</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>Breast</td>\n",
       "      <td>MRRF</td>\n",
       "      <td>Dr.Nod 2023</td>\n",
       "      <td>test1116</td>\n",
       "      <td>1</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058</th>\n",
       "      <td>9</td>\n",
       "      <td>124049461</td>\n",
       "      <td>124049462</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>Breast</td>\n",
       "      <td>MRRF</td>\n",
       "      <td>Dr.Nod 2023</td>\n",
       "      <td>test1117</td>\n",
       "      <td>1</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>X</td>\n",
       "      <td>70338403</td>\n",
       "      <td>70338404</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>Brain</td>\n",
       "      <td>MED12</td>\n",
       "      <td>Dr.Nod 2023</td>\n",
       "      <td>test1118</td>\n",
       "      <td>1</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>X</td>\n",
       "      <td>70401837</td>\n",
       "      <td>70401838</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>Brain</td>\n",
       "      <td>MED12</td>\n",
       "      <td>Dr.Nod 2023</td>\n",
       "      <td>test1119</td>\n",
       "      <td>1</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>X</td>\n",
       "      <td>70365659</td>\n",
       "      <td>70365660</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>Brain</td>\n",
       "      <td>MED12</td>\n",
       "      <td>Dr.Nod 2023</td>\n",
       "      <td>test1120</td>\n",
       "      <td>1</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1062 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     chr      start        end ref alt    region_type  \\\n",
       "0     11  111231125  111231125   G   C  enhancers.bed   \n",
       "1     11  111232885  111232885   C   T  enhancers.bed   \n",
       "2      7   86866372   86866372   T   C  enhancers.bed   \n",
       "3      1    2267139    2267139   G   A  enhancers.bed   \n",
       "4     11  111226848  111226848   T   C  enhancers.bed   \n",
       "...   ..        ...        ...  ..  ..            ...   \n",
       "1057   9  125026995  125026996   C   G         Breast   \n",
       "1058   9  124049461  124049462   T   A         Breast   \n",
       "1059   X   70338403   70338404   G   A          Brain   \n",
       "1060   X   70401837   70401838   G   T          Brain   \n",
       "1061   X   70365659   70365660   G   A          Brain   \n",
       "\n",
       "                                            reg_id          data_source  \\\n",
       "0     enhancers::chr11:111222000-111233000::NA::NA  Rheinbay et al 2020   \n",
       "1     enhancers::chr11:111222000-111233000::NA::NA  Rheinbay et al 2020   \n",
       "2        enhancers::chr7:86865600-86866400::NA::NA  Rheinbay et al 2020   \n",
       "3          enhancers::chr1:2267000-2269600::NA::NA  Rheinbay et al 2020   \n",
       "4     enhancers::chr11:111222000-111233000::NA::NA  Rheinbay et al 2020   \n",
       "...                                            ...                  ...   \n",
       "1057                                          MRRF          Dr.Nod 2023   \n",
       "1058                                          MRRF          Dr.Nod 2023   \n",
       "1059                                         MED12          Dr.Nod 2023   \n",
       "1060                                         MED12          Dr.Nod 2023   \n",
       "1061                                         MED12          Dr.Nod 2023   \n",
       "\n",
       "            id  driver qual filter info format  \n",
       "0        test0       1    .      .    .      .  \n",
       "1        test1       1    .      .    .      .  \n",
       "2        test2       1    .      .    .      .  \n",
       "3        test3       1    .      .    .      .  \n",
       "4        test4       1    .      .    .      .  \n",
       "...        ...     ...  ...    ...  ...    ...  \n",
       "1057  test1116       1    .      .    .      .  \n",
       "1058  test1117       1    .      .    .      .  \n",
       "1059  test1118       1    .      .    .      .  \n",
       "1060  test1119       1    .      .    .      .  \n",
       "1061  test1120       1    .      .    .      .  \n",
       "\n",
       "[1062 rows x 14 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df[df['known_driver_gene_2kb_downstream'].isna()]\n",
    "# df_vep_output_test\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_vep_output.merge(df, left_on=['#Uploaded_variation', 'chr', 'start', 'end'], right_on=['id', 'chr', 'start', 'end'], how='right')\n",
    "data_test = df_vep_output_test.merge(test_df, left_on=['#Uploaded_variation'], right_on=['id'], how='right')\n",
    "data.drop(['#Uploaded_variation', 'Location'],inplace = True, axis = 1)\n",
    "data_test.drop(['#Uploaded_variation', 'Location'],inplace = True, axis = 1)\n",
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('data/final_dataset.csv', index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/final_dataset.csv')\n",
    "data\n",
    "# df = data[data['driver'] == 1]\n",
    "# negdf = data[data['driver'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['TF_binding_site_agg'] = np.logical_or(data['TF_binding_site'], data['TF_binding_site_variant']).astype(int)\n",
    "\n",
    "data['TF_loss_add'] = data['TF_binding_site_agg'] + data['TF_loss']\n",
    "data['TF_gain_add'] = data['TF_binding_site_agg'] + data['TF_gain']\n",
    "data['TF_loss_diff_add'] = data['TF_binding_site_agg'] + data['TF_loss_diff']\n",
    "data['TF_gain_diff_add'] = data['TF_binding_site_agg'] + data['TF_gain_diff']\n",
    "\n",
    "data['SpliceAI_pred_DP_AG'] = abs(data['SpliceAI_pred_DP_AG'])\n",
    "data['SpliceAI_pred_DP_AL'] = abs(data['SpliceAI_pred_DP_AL'])\n",
    "data['SpliceAI_pred_DP_DG'] = abs(data['SpliceAI_pred_DP_DG'])\n",
    "data['SpliceAI_pred_DP_DL'] = abs(data['SpliceAI_pred_DP_DL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1084    0\n",
       "1085    0\n",
       "1086    0\n",
       "1087    0\n",
       "1088    1\n",
       "Name: driver, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB_PARAMS = {                                            # CODE SOURCE: containers_build\\boostdm\\config.py\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"reg_lambda\": 1,\n",
    "        \"random_state\": 42,\n",
    "        \"scale_pos_weight\": 1,\n",
    "        \"subsample\": 0.7,        # fraction of observations to be random samples for each tree\n",
    "        \"reg_alpha\": 0,          # L1 regularization term on weight\n",
    "        \"max_delta_step\": 0,    # positive value can help make the update step more conservative. generally not used\n",
    "        \"min_child_weight\": 1,\n",
    "        \"learning_rate\": 1e-03,\n",
    "        \"colsample_bylevel\": 1.0,\n",
    "        \"gamma\": 0,     # specifies the minimum loss reduction required to make a split. Makes the algorithm conservative\n",
    "        \"colsample_bytree\": 1.0,        # fraction of columns to be random samples for each tree\n",
    "        \"booster\": \"gbtree\",\n",
    "        \"max_depth\": 4, # Used to control over-fitting as higher depth will allow the model to learn relations very specific to a particular sample\n",
    "        \"silent\": 1,\n",
    "        \"seed\": 21,\n",
    "        \"eval_metric\": 'logloss',\n",
    "        \"early_stopping_rounds\": 2000\n",
    "        # \"reg_lambda\": 1,  # explore this further\n",
    "\n",
    "}\n",
    "\n",
    "# 'ada_score', 'rf_score', 'CADD_PHRED', 'CADD_RAW', 'MODERATE', 'LOW', 'SWISSPROT', 'TREMBL', 'miRNA', 'sense_overlapping', 'misc_RNA'\n",
    "# 'IG_D_gene', 'IG_J_gene', 'IG_C_gene', 'transcribed_unprocessed_pseudogene', 'non_stop_decay', '3prime_overlapping_ncRNA', 'pseudogene', 'transcribed_processed_pseudogene', 'rNA'\n",
    "# 'missense_variant', 'synonymous_variant', 'stop_gained', 'stop_lost', 'splice_region_variant', 'inframe_insertion', 'start_lost', 'inframe_deletion', 'frameshift_variant' # not in positive set\n",
    "# 'splice_acceptor_variant', 'coding_sequence_variant', 'splice_donor_region_variant', 'splice_donor_5th_base_variant' # not in negative set\n",
    "# open_chromatin_region, 'snRNA', 'snoRNA' # not enough values\n",
    "# 'STRAND', 'TF_binding_site_variant', 'TF_binding_site', \n",
    "\n",
    "COLUMNS_TRAINING = ['ada_score', 'rf_score',\n",
    "        'ENSP', 'UNIPARC', 'GO',\n",
    "       'LOEUF', 'SpliceAI_pred_DP_AG', 'SpliceAI_pred_DP_AL',\n",
    "       'SpliceAI_pred_DP_DG', 'SpliceAI_pred_DP_DL', 'SpliceAI_pred_DS_AG',\n",
    "       'SpliceAI_pred_DS_AL', 'SpliceAI_pred_DS_DG', 'SpliceAI_pred_DS_DL',\n",
    "       '3_prime_UTR_variant', '5_prime_UTR_variant',\n",
    "       'NMD_transcript_variant', \n",
    "       'downstream_gene_variant',\n",
    "       'intergenic_variant', 'intron_variant',\n",
    "       'non_coding_transcript_exon_variant', 'non_coding_transcript_variant',\n",
    "       'regulatory_region_variant',\n",
    "       'splice_donor_variant', 'splice_polypyrimidine_tract_variant',\n",
    "       'upstream_gene_variant', 'MODIFIER', 'MotifFeature',\n",
    "       'RegulatoryFeature', 'Transcript', 'CTCF_binding_site',\n",
    "       'enhancer', 'nonsense_mediated_decay',\n",
    "       'processed_pseudogene', 'processed_transcript', 'promoter',\n",
    "       'protein_coding', 'retained_intron',\n",
    "       'unprocessed_pseudogene',\n",
    "       'CTCF_interactions', 'CTCF_chains', 'POLR2A_interactions', 'POLR2A_chains',\n",
    "       'DNA', 'LINE', 'LTR', 'SINE', 'Simple_repeat',\n",
    "       'known_driver_gene', 'known_driver_gene_100kb_downstream', 'known_driver_gene_100kb_upstream', 'known_driver_gene_10kb_downstream',\n",
    "       'known_driver_gene_10kb_upstream', 'known_driver_gene_2kb_downstream', 'known_driver_gene_2kb_upstream',\n",
    "       'splice_acceptor_variant', 'splice_donor_region_variant', 'splice_donor_5th_base_variant',\n",
    "       'missense_variant', 'synonymous_variant', 'stop_gained', 'stop_lost', 'splice_region_variant', 'inframe_insertion', 'frameshift_variant',\n",
    "       'TF_loss_add', 'TF_gain_add', 'TF_loss_diff_add', 'TF_gain_diff_add'\n",
    "    ]\n",
    "\n",
    "# BIASED_COLUMNS = list(df.loc[:, df.nunique() == 1].columns) + list(negdf.loc[:, negdf.nunique() == 1].columns)\n",
    "BIASED_COLUMNS = ['chr', 'ref_x', 'IG_C_gene', 'IG_D_gene', 'IG_J_gene', 'IG_J_pseudogene']\n",
    "# BIASED_COLUMNS.remove('driver')\n",
    "# BIASED_COLUMNS.remove('driver')\n",
    "# BIASED_COLUMNS.remove('splice_acceptor_variant')\n",
    "\n",
    "COLUMNS_TRAINING = [x for x in COLUMNS_TRAINING if x not in BIASED_COLUMNS]\n",
    "\n",
    "COLUMNS_SHAP = [f'my_shap_{x}' for x in COLUMNS_TRAINING]\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "data[COLUMNS_TRAINING] = min_max_scaler.fit_transform(data[COLUMNS_TRAINING])\n",
    "\n",
    "valset = data[-5:]\n",
    "data = data[:-5]\n",
    "valset['driver']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allele\n",
      "SYMBOL\n",
      "STRAND\n",
      "ENSP\n",
      "UNIPARC\n",
      "LOEUF\n",
      "SpliceAI_pred_DP_AG\n",
      "SpliceAI_pred_DP_AL\n",
      "SpliceAI_pred_DP_DG\n",
      "SpliceAI_pred_DP_DL\n",
      "SpliceAI_pred_DS_AG\n",
      "SpliceAI_pred_DS_AL\n",
      "SpliceAI_pred_DS_DG\n",
      "SpliceAI_pred_DS_DL\n",
      "GO\n",
      "CADD_PHRED\n",
      "CADD_RAW\n",
      "ada_score\n",
      "rf_score\n",
      "3_prime_UTR_variant\n",
      "5_prime_UTR_variant\n",
      "NMD_transcript_variant\n",
      "TF_binding_site_variant\n",
      "downstream_gene_variant\n",
      "frameshift_variant\n",
      "inframe_insertion\n",
      "intergenic_variant\n",
      "intron_variant\n",
      "missense_variant\n",
      "non_coding_transcript_exon_variant\n",
      "non_coding_transcript_variant\n",
      "regulatory_region_variant\n",
      "splice_acceptor_variant\n",
      "splice_donor_5th_base_variant\n",
      "splice_donor_region_variant\n",
      "splice_donor_variant\n",
      "splice_polypyrimidine_tract_variant\n",
      "splice_region_variant\n",
      "stop_gained\n",
      "stop_lost\n",
      "stop_retained_variant\n",
      "synonymous_variant\n",
      "upstream_gene_variant\n",
      "HIGH\n",
      "LOW\n",
      "MODERATE\n",
      "MODIFIER\n",
      "MotifFeature\n",
      "RegulatoryFeature\n",
      "Transcript\n",
      "CTCF_binding_site\n",
      "IG_C_gene\n",
      "IG_V_gene\n",
      "IG_V_pseudogene\n",
      "TEC\n",
      "TF_binding_site\n",
      "TR_V_gene\n",
      "enhancer\n",
      "lncRNA\n",
      "miRNA\n",
      "misc_RNA\n",
      "nonsense_mediated_decay\n",
      "open_chromatin_region\n",
      "processed_pseudogene\n",
      "processed_transcript\n",
      "promoter\n",
      "protein_coding\n",
      "protein_coding_CDS_not_defined\n",
      "protein_coding_LoF\n",
      "rRNA_pseudogene\n",
      "retained_intron\n",
      "ribozyme\n",
      "snRNA\n",
      "snoRNA\n",
      "transcribed_unitary_pseudogene\n",
      "transcribed_unprocessed_pseudogene\n",
      "unitary_pseudogene\n",
      "unprocessed_pseudogene\n",
      "chr_x\n",
      "start_x\n",
      "end_x\n",
      "chr_y\n",
      "start_y\n",
      "ref\n",
      "alt\n",
      "id\n",
      "end_y\n",
      "driver\n",
      "data_source\n",
      "DNA\n",
      "LINE\n",
      "LTR\n",
      "SINE\n",
      "Simple_repeat\n",
      "known_driver_gene\n",
      "known_driver_gene_100kb_downstream\n",
      "known_driver_gene_100kb_upstream\n",
      "known_driver_gene_10kb_downstream\n",
      "known_driver_gene_10kb_upstream\n",
      "known_driver_gene_2kb_downstream\n",
      "known_driver_gene_2kb_upstream\n",
      "TF_loss\n",
      "TF_gain\n",
      "TF_loss_diff\n",
      "TF_gain_diff\n",
      "CTCF_interactions\n",
      "CTCF_chains\n",
      "POLR2A_interactions\n",
      "POLR2A_chains\n",
      "TF_binding_site_agg\n",
      "TF_loss_add\n",
      "TF_gain_add\n",
      "TF_loss_diff_add\n",
      "TF_gain_diff_add\n"
     ]
    }
   ],
   "source": [
    "for c in data.columns:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(COLUMNS_TRAINING)\n",
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS_TRAINING_LABELS = [item[:14] + '\\n' + item[14:] for item in COLUMNS_TRAINING]\n",
    "\n",
    "fig, (ax1, ax2, ax3, ax4, ax5, ax6) = plt.subplots(nrows=6, ncols=1, figsize=(30, 60))\n",
    "\n",
    "bplot1 = ax1.boxplot(data[COLUMNS_TRAINING].iloc[:, 0:10],\n",
    "                     vert=True,\n",
    "                     patch_artist=True,\n",
    "                     boxprops = dict(facecolor = \"lightblue\"),\n",
    "                     capprops = dict(color = \"red\", linewidth = 4),\n",
    "                     labels=COLUMNS_TRAINING_LABELS[0:10])\n",
    "\n",
    "bplot2 = ax2.boxplot(data[COLUMNS_TRAINING].iloc[:, 10:20],\n",
    "                     vert=True,\n",
    "                     patch_artist=True,\n",
    "                     boxprops = dict(facecolor = \"lightblue\"),\n",
    "                     capprops = dict(color = \"red\", linewidth = 4),\n",
    "                     labels=COLUMNS_TRAINING_LABELS[10:20])\n",
    "\n",
    "bplot3 = ax3.boxplot(data[COLUMNS_TRAINING].iloc[:, 20:30],\n",
    "                     vert=True,\n",
    "                     patch_artist=True,\n",
    "                     boxprops = dict(facecolor = \"lightblue\"),\n",
    "                     capprops = dict(color = \"red\", linewidth = 4),\n",
    "                     labels=COLUMNS_TRAINING_LABELS[20:30])\n",
    "\n",
    "bplot4 = ax4.boxplot(data[COLUMNS_TRAINING].iloc[:, 30:40],\n",
    "                     vert=True,\n",
    "                     patch_artist=True,\n",
    "                     boxprops = dict(facecolor = \"lightblue\"),\n",
    "                     capprops = dict(color = \"red\", linewidth = 4),\n",
    "                     labels=COLUMNS_TRAINING_LABELS[30:40])\n",
    "\n",
    "bplot5 = ax5.boxplot(data[COLUMNS_TRAINING].iloc[:, 40:50],\n",
    "                     vert=True,\n",
    "                     patch_artist=True,\n",
    "                     boxprops = dict(facecolor = \"lightblue\"),\n",
    "                     capprops = dict(color = \"red\", linewidth = 4),\n",
    "                     labels=COLUMNS_TRAINING_LABELS[40:50])\n",
    "\n",
    "bplot6 = ax6.boxplot(data[COLUMNS_TRAINING].iloc[:, 50:len(COLUMNS_TRAINING)],\n",
    "                     vert=True,\n",
    "                     patch_artist=True,\n",
    "                     boxprops = dict(facecolor = \"lightblue\"),\n",
    "                     capprops = dict(color = \"red\", linewidth = 4),\n",
    "                     labels=COLUMNS_TRAINING_LABELS[50:])\n",
    "\n",
    "# adding horizontal grid lines\n",
    "for ax in [ax1, ax2, ax3, ax4, ax5, ax6]:\n",
    "    ax.yaxis.grid(True)\n",
    "    ax.set_xlabel('Features', fontsize=20)\n",
    "    ax.set_ylabel('Normalized Observed values', fontsize=20)\n",
    "    ax.tick_params(axis='y', labelsize=20)\n",
    "    ax.tick_params(axis='x', labelsize=20)\n",
    "\n",
    "fig.suptitle('Boxplot Normalised Dataset', fontsize=30)\n",
    "fig.tight_layout(pad=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS_TRAINING_LABELS = [item[:14] + '\\n' + item[14:] for item in COLUMNS_TRAINING]\n",
    "num = 8\n",
    "col = 0\n",
    "fig, axes = plt.subplots(nrows=8, ncols=8, figsize=(30, 30))\n",
    "for i in range(0, num):\n",
    "    for j in range(0, num):\n",
    "        colour_dict = {0: 'pink', 1: 'lightblue'}\n",
    "        axes[i][j].hist([data.loc[data['driver'] == x, COLUMNS_TRAINING[col]] for x in colour_dict.keys()],\n",
    "                color=[colour_dict[x] for x in colour_dict.keys()],\n",
    "                edgecolor='black',\n",
    "                stacked=True)\n",
    "        axes[i][j].set_xlabel(COLUMNS_TRAINING_LABELS[col], fontsize=20, wrap=True)\n",
    "        axes[i][j].tick_params(axis='y', labelsize=15)\n",
    "        axes[i][j].tick_params(axis='x', labelsize=15)\n",
    "\n",
    "        col = col + 1\n",
    "        if col >= len(COLUMNS_TRAINING):\n",
    "            break\n",
    "\n",
    "fig.suptitle('Histogram of Normalised Dataset', fontsize=30)\n",
    "fig.legend(colour_dict, labels=['non-driver', 'driver'], loc='upper left', ncol = 2, fontsize=20)\n",
    "fig.tight_layout(pad=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS_WITH_DRIVER = COLUMNS_TRAINING\n",
    "COLUMNS_WITH_DRIVER.append('driver')\n",
    "corr_matrix = data[COLUMNS_TRAINING].corr()\n",
    "matrix = np.triu(corr_matrix)\n",
    "sns.set(font_scale=0.6)\n",
    "# sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "sns.set(rc={'figure.figsize':(30,30)})\n",
    "# sns.set(rc=)\n",
    "\n",
    "ax= sns.heatmap(corr_matrix, mask=matrix, vmin=-1, vmax=+1, center=0,\n",
    "            square=True, linewidths=.1, cbar_kws={\"shrink\": .82},annot=True,\n",
    "            fmt='.1',annot_kws={\"size\":7}, cmap='coolwarm')\n",
    "\n",
    "sns.set()\n",
    "for t in ax.texts:\n",
    "    if float(t.get_text())>=0.4 or float(t.get_text())<=-0.4:\n",
    "        t.set_text(t.get_text()) #if the value is greater than 0.4 then I set the text \n",
    "    else:\n",
    "        t.set_text(\"\") # if not it sets an empty text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sweep using WANDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from scipy.stats import ks_2samp\n",
    "import wandb\n",
    "from wandb.xgboost import WandbCallback\n",
    "import os\n",
    "os.environ[\"WANDB_API_KEY\"] = '8760ac6e727d4e8b826bb6a5fd5bdf3e2d662a40'\n",
    "\n",
    "xgboost.set_config(verbosity=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "  \"method\" : \"grid\",\n",
    "  \"parameters\" : {\n",
    "    \"learning_rate\" :{\n",
    "      \"values\": [0.001, 0.005, 0.01]\n",
    "    },\n",
    "    \"early_stopping_rounds\" :{\n",
    "      \"values\" : [1000, 2000, 4000]\n",
    "    },\n",
    "    \"subsample\": {    # fraction of observations to be random samples for each tree\n",
    "      \"values\": [0.5, 0.7, 0.8, 1.0]\n",
    "    },\n",
    "    \"max_depth\": {\n",
    "      \"values\": [4, 6]  \n",
    "    }, # Used to control over-fitting as higher depth will allow the model to learn relations very specific to a particular sample\n",
    "  }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project='thesis', entity='sanabasharat')\n",
    "\n",
    "def train():\n",
    "  with wandb.init(job_type=\"sweep\") as run:\n",
    "    # for i in list_cvs: # for each of the 50 splits\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data[COLUMNS_TRAINING], data['driver'],\n",
    "                                                        random_state=104, \n",
    "                                                        test_size=0.25, \n",
    "                                                        shuffle=True)         # CODE SOURCE: containers_build\\boostdm\\training.py LIN 44\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=104) # 0.25 x 0.8 = 0.2\n",
    "    \n",
    "    bst_params = {\n",
    "        'objective': 'binary:logistic'\n",
    "        , 'base_score': y_train.mean()\n",
    "        , 'gamma': 0\n",
    "        , 'learning_rate': run.config['learning_rate']\n",
    "        , 'max_depth': 3\n",
    "        , 'n_estimators': 20000\n",
    "        , 'random_state': 42\n",
    "        , 'early_stopping_rounds': run.config['early_stopping_rounds']\n",
    "        , 'eval_metric': 'logloss'\n",
    "        , 'subsample': run.config['subsample']\n",
    "        , 'max_depth': run.config['max_depth']\n",
    "        , 'reg_lambda': 1\n",
    "        , 'random_state': 42\n",
    "        , 'scale_pos_weight': 1\n",
    "        , 'silent': 1\n",
    "        , 'seed': 21\n",
    "        , 'reg_alpha': 0         # L1 regularization term on weight\n",
    "        , 'max_delta_step': 0    # positive value can help make the update step more conservative. generally not used\n",
    "        , 'min_child_weight': 1\n",
    "        , 'colsample_bylevel': 1.0\n",
    "        , 'colsample_bytree': 1.0        # fraction of columns to be random samples for each tree\n",
    "        , 'booster': 'gbtree'\n",
    "        , 'n_jobs' : 1\n",
    "        , 'min_child_weight': 1\n",
    "    }\n",
    "    # params = XGB_PARAMS.copy()                                          \n",
    "    # params['n_estimators'] = 20000  # set it high enough to allow \"early stopping\" events below\n",
    "    # params['base_score'] = y_train.mean()\n",
    "    # params['n_jobs'] = 1\n",
    "    # params['seed'] = seed\n",
    "    model = XGBClassifier(**bst_params)\n",
    "\n",
    "    # train with xgboost\n",
    "    # learning_curve_dict = {}\n",
    "    model.fit(x_train, y_train, eval_set=[(x_train, y_train), (x_test, y_test)],\n",
    "                        callbacks = [\n",
    "                            xgboost.callback.EvaluationMonitor(rank=0, period=1, show_stdv=False),\n",
    "                            WandbCallback()\n",
    "                        ],\n",
    "                        verbose = 0)\n",
    "\n",
    "    bst_params['n_estimators'] = model.best_iteration\n",
    "    model.set_params(**bst_params)\n",
    "    \n",
    "    bstr = model.get_booster()\n",
    "\n",
    "    # Log booster metrics\n",
    "    run.summary[\"best_ntree_limit\"] = bstr.best_ntree_limit\n",
    "    \n",
    "    # Get train and validation predictions\n",
    "    trnYpreds = model.predict_proba(x_train)[:,1]\n",
    "    valYpreds = model.predict_proba(x_val)[:,1] \n",
    "\n",
    "    # Log additional Train metrics\n",
    "    false_positive_rate, true_positive_rate, thresholds = metrics.roc_curve(y_train, trnYpreds) \n",
    "    run.summary['train_ks_stat'] = max(true_positive_rate - false_positive_rate)\n",
    "    run.summary['train_auc'] = metrics.auc(false_positive_rate, true_positive_rate)\n",
    "    run.summary['train_log_loss'] = -(y_train * np.log(trnYpreds) + (1-y_train) * np.log(1-trnYpreds)).sum() / len(y_train)\n",
    "\n",
    "    # Log additional Validation metrics\n",
    "    ks_stat, ks_pval = ks_2samp(valYpreds[y_val==1], valYpreds[y_val==0])\n",
    "    run.summary[\"val_ks_2samp\"] = ks_stat\n",
    "    run.summary[\"val_ks_pval\"] = ks_pval\n",
    "    run.summary[\"val_auc\"] = metrics.roc_auc_score(y_val, valYpreds)\n",
    "    run.summary[\"val_acc_0.5\"] = metrics.accuracy_score(y_val, np.where(valYpreds >= 0.5, 1, 0))\n",
    "    run.summary[\"val_log_loss\"] = -(y_val * np.log(valYpreds) + (1-y_val) * np.log(1-valYpreds)).sum() / len(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = 10 # number of runs to execute\n",
    "wandb.agent(sweep_id, function=train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data[COLUMNS_TRAINING], data['driver'],\n",
    "                                                    random_state=104, \n",
    "                                                    test_size=0.25, \n",
    "                                                    shuffle=True)         # CODE SOURCE: containers_build\\boostdm\\training.py LIN 44\n",
    "# x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=104) # 0.25 x 0.8 = 0.2\n",
    "\n",
    "params = XGB_PARAMS.copy()                                          \n",
    "params['n_estimators'] = 20000  # set it high enough to allow \"early stopping\" events below\n",
    "params['base_score'] = y_train.mean()\n",
    "params['silent'] = True\n",
    "# params['n_jobs'] = 1\n",
    "params['seed'] = 104\n",
    "model = XGBClassifier(**params)\n",
    "\n",
    "# train with xgboost\n",
    "# learning_curve_dict = {}\n",
    "model.fit(x_train, y_train, eval_set=[(x_train, y_train), (x_test, y_test)],\n",
    "                    callbacks = [\n",
    "                        xgboost.callback.EvaluationMonitor(rank=0, period=1, show_stdv=False)\n",
    "                    ],\n",
    "                    verbose = 1)\n",
    "\n",
    "params['n_estimators'] = model.best_iteration\n",
    "model.set_params(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evals_result()\n",
    "epochs = len(results['validation_0']['logloss'])\n",
    "x_axis = range(0, epochs)\n",
    "fig, ax = plt.subplots(figsize=(4, 3))\n",
    "ax.plot(x_axis, results['validation_0']['logloss'], label='Train', color='blue', linewidth = '1')\n",
    "ax.plot(x_axis, results['validation_1']['logloss'], label='Test', color='red', linewidth = '1')\n",
    "ax.legend()\n",
    "plt.ylabel('logloss',{'fontname':'Cambria'})\n",
    "plt.xlabel('n_estimators',{'fontname':'Cambria'})\n",
    "# plt.title('XGBoost logloss', {'fontname':'Cambria'})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(x_test)\n",
    "score = accuracy_score(y_test, yhat)\n",
    "print('Accuracy: %.3f' % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss(yhat, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import seed\n",
    "from random import randrange\n",
    " \n",
    "# zero rule algorithm for classification\n",
    "def zero_rule_algorithm_classification(train, test):\n",
    " output_values = [row[-1] for row in train]\n",
    " prediction = max(set(output_values), key=output_values.count)\n",
    " predicted = [prediction for i in range(len(test))]\n",
    " return predicted\n",
    "\n",
    "train = x_train\n",
    "train['driver'] = y_train\n",
    "test = x_test\n",
    "test['driver'] = y_test\n",
    "seed(1)\n",
    "# train = [['0'], ['0'], ['0'], ['0'], ['1'], ['1']]\n",
    "# test = [[None], [None], [None], [None]]\n",
    "predictions = zero_rule_algorithm_classification(train, test)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['driver'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print('precision: ', precision_score(y_test, yhat))\n",
    "print('recall: ' , recall_score(y_test, yhat))\n",
    "print('f1_score: ', f1_score(y_test, yhat))\n",
    "print('roc_auc_score: ', roc_auc_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_matrix = confusion_matrix(y_true=y_test, y_pred=yhat)\n",
    "#\n",
    "# Print the confusion matrix using Matplotlib\n",
    "#\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.matshow(conf_matrix, cmap=plt.cm.Oranges, alpha=0.3)\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
    " \n",
    "plt.xlabel('Predictions', fontsize=18)\n",
    "plt.ylabel('Actuals', fontsize=18)\n",
    "plt.title('Confusion Matrix', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valsetpred = model.predict(valset[COLUMNS_TRAINING])\n",
    "print(valset['driver'])\n",
    "print(valsetpred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SHAP Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP attribution\n",
    "x_data = data[COLUMNS_TRAINING]\n",
    "\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(x_data)\n",
    "# shap_values = np.mean(shap_bootstrap, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in COLUMNS_SHAP:\n",
    "    data[c] = np.nan\n",
    "data.loc[data.index, COLUMNS_SHAP] = shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data[['splice_acceptor_variant', 'splice_donor_variant', 'promoter', 'downstream_gene_variant', 'regulatory_region_variant']]#.describe()\n",
    "# x_data.columns.get_loc('splice_acceptor_variant')\n",
    "# x_data.columns.get_loc('splice_donor_variant')\n",
    "# x_data.columns.get_loc('LOEUF')\n",
    "data['driver'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values[:,[60, 24, 38, 17, 23]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap.summary_plot(shap_values[:,2:5], x_data.iloc[:, 2:5], plot_size = 0.25)  # protein product\n",
    "# shap.summary_plot(shap_values[:,6:14], x_data.iloc[:, 6:14], plot_size = 0.25)  # splice ai\n",
    "# shap.summary_plot(shap_values[:,0:2], x_data.iloc[:, 0:2], plot_size = 0.25) #ada score rf score\n",
    "shap.summary_plot(shap_values[:,44:48], x_data.iloc[:, 44:48], plot_size = 0.25)  # interactions\n",
    "# shap.summary_plot(shap_values[:,53:60], x_data.iloc[:, 53:60], plot_size = 0.25) # cosmic genes\n",
    "# shap.summary_plot(shap_values[:,48:53], x_data.iloc[:, 48:53], plot_size = 0.25) #repeat masker\n",
    "# shap.summary_plot(shap_values[:,73:77], x_data.iloc[:, 73:77], plot_size = 0.25)  # tf\n",
    "# shap.summary_plot(shap_values[:,5:6], x_data.iloc[:, 5:6], plot_size = 0.25)  # loeuf\n",
    "# shap.summary_plot(shap_values[:,[60, 24, 38, 17, 23]], x_data.iloc[:, [60, 24, 38, 17, 23]], plot_size = 0.25) # the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, x_data, max_display=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(\"CTCF_interactions\", shap_values, x_data, interaction_index=\"CTCF_chains\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap.plots.heatmap(shap_values)\n",
    "shap_values_explaination = shap.Explanation(shap_values, feature_names=data[COLUMNS_TRAINING].columns.tolist()) \n",
    "shap.plots.heatmap(shap_values_explaination, max_display=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = data[COLUMNS_TRAINING]\n",
    "explainer = shap.TreeExplainer(model) # grabbing the first model\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value, shap_values[101:200], x_data[101:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importances = pd.Series(model.feature_importances_, index=data[COLUMNS_TRAINING].columns)\n",
    "feat_importances.nlargest(40).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from anytree import Node, RenderTree, AsciiStyle, LevelGroupOrderIter, LevelOrderGroupIter, search\n",
    "from intervaltree import Interval, IntervalTree\n",
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "def read_dataset():\n",
    "    df_pos = pd.read_csv('artifacts/df_grch38.bed', sep='\\t', header=None)\n",
    "    df_pos.columns = ['chr', 'start', 'end']\n",
    "\n",
    "    orig = pd.read_csv('ICGC_TCGA_noncoding_data.csv')\n",
    "    df_pos['pos_37'] = orig['pos']\n",
    "    df_pos.drop_duplicates(keep='first', inplace=True)\n",
    "\n",
    "    df_neg = pd.read_csv('negdf_grch38.bed', sep='\\t', header=None)\n",
    "    df_neg.columns = ['chr', 'start', 'end', 'old_pos', 'bed_format']\n",
    "    df_neg['chr'] = df_neg['chr'].apply(lambda x: x.replace('chr', ''))\n",
    "    df_neg['chr_old'] = df_neg['old_pos'].str.split(':').str[0].str.replace('chr', '')\n",
    "    df_neg['start_old'] = df_neg['old_pos'].str.split(':').str[1].str.split('-').str[1]\n",
    "    df_neg['end_old'] = df_neg['old_pos'].str.split(':').str[1].str.split('-').str[0]\n",
    "    df_neg['start_old'] = pd.to_numeric(df_neg['start_old'])\n",
    "    df_neg['end_old'] = pd.to_numeric(df_neg['end_old'])\n",
    "    metadata = pd.read_csv(r'C:\\Users\\Sana\\Downloads\\ChiaPET\\metadata.tsv', sep='\\t')\n",
    "\n",
    "    df_pos = df_pos[['chr', 'start', 'end', 'pos_37']]\n",
    "    df_pos['driver'] = 1\n",
    "    df_pos.drop_duplicates(keep='first', inplace=True)\n",
    "\n",
    "    df_neg = df_neg[['chr', 'start', 'end', 'start_old']]\n",
    "    df_neg['driver'] = 0\n",
    "    df_neg.rename(columns = {'start_old': 'pos_37'}, inplace = True)\n",
    "    df_neg.drop_duplicates(keep='first', inplace=True)\n",
    "\n",
    "    df = pd.concat([df_pos, df_neg])\n",
    "    return df                              # final dataset including negative and positive set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_dataset()\n",
    "df.sort_values('chr', inplace=True)\n",
    "df.reset_index(drop = True, inplace = True)\n",
    "df['CTCF_interactions'] = 0\n",
    "df['CTCF_chains'] = 0\n",
    "df['POLR2A_interactions'] = 0\n",
    "df['POLR2A_chains'] = 0\n",
    "\n",
    "chr = '17'\n",
    "mutation = 50862973\n",
    "all_files = ['ENCFF271VMZ.bedpe']\n",
    "for file in all_files:\n",
    "    print(file)\n",
    "    cp = pd.read_csv('C:/Users/Sana/Downloads/ChiaPET/' + file, sep = '\\t',  header = None)\n",
    "    cp.columns = ['chr_A', 'start_A', 'end_A', 'chr_B', 'start_B', 'end_B', 'score']\n",
    "    cp['chr_A'] = cp['chr_A'].map(lambda x: x.replace('chr', ''))\n",
    "    cp['chr_B'] = cp['chr_B'].map(lambda x: x.replace('chr', ''))\n",
    "    \n",
    "    cp = cp[cp['chr_A'] == chr]\n",
    "    interactions_tree = IntervalTree()\n",
    "\n",
    "    for index, row in cp.iterrows():\n",
    "        interactions_tree.add(Interval(row['start_A'], row['end_A'], tuple([row['chr_A'], row['start_B'], row['end_B']]))) # fotwards interaction\n",
    "        interactions_tree.add(Interval(row['start_B'], row['end_B'], tuple([row['chr_A'], row['start_A'], row['end_A']]))) # backwards interaction\n",
    "        \n",
    "    # df_tree = []\n",
    "    \n",
    "    # save_tree = interactions_tree.copy()\n",
    "    # for index, row in df.iterrows():          # this is to make an AnyTree for each mutation in the dataset, and store them all in a list\n",
    "    #     df_tree.append(Node(name = row['chr'] + ':' + str(row['start']) + '-' + str(row['end']), chr = row['chr'], start = row['start'], end = row['end'], checked = 0))\n",
    "\n",
    "    # #checking just one mutation\n",
    "    # df_tree = Node(name = 'artificial', chr = '17', start = 59210051, end = 59210052, checked = 0)\n",
    "    df_tree = Node(name = 'artificial', checked = 0)\n",
    "    # df_tree = Node(name = 'artificial', chr = '3', start = 5, end = 6, checked = 0)     # checking just one artificial mutation\n",
    "\n",
    "    found_overlap = False\n",
    "    if len(interactions_tree.at(mutation)) > 0:\n",
    "        found_overlap = True\n",
    "        for i in interactions_tree.at(mutation):\n",
    "            Node(Interval(i.data[1], i.data[2]), checked = 0, parent = df_tree)\n",
    "            interactions_tree.remove(i)\n",
    "            inv = Interval(i.data[1], i.data[2], tuple([i.data[0], i.begin, i.end]))\n",
    "            interactions_tree.remove(inv)\n",
    "\n",
    "    interactions = 0\n",
    "    chains = 0\n",
    "    if found_overlap:\n",
    "        children_left = True\n",
    "        while children_left is True:\n",
    "            children_left = False\n",
    "            for node in df_tree.leaves:\n",
    "                if node.checked == 0:\n",
    "                    node.checked = 1\n",
    "                    found_list = list(interactions_tree.overlap(node.name))\n",
    "                    for found_node in found_list:\n",
    "                        print(\"FOUND: \", found_node)\n",
    "                        children_left = True\n",
    "                        Node(name = Interval(found_node.data[1], found_node.data[2]), checked = 0, parent = node)\n",
    "                        print(\"REMOVING: \", found_node)\n",
    "                        try:\n",
    "                            interactions_tree.remove(found_node)# only remove that node which satisfies both conditions of similarity\n",
    "                        except:\n",
    "                            pass\n",
    "                        try:\n",
    "                            interactions_tree.remove(Interval(found_node.data[1], found_node.data[2], tuple([found_node.data[0], found_node.begin, found_node.end])))\n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "        interactions = len(set([k.name for k in df_tree.descendants]))\n",
    "        chains = sum(len(x) for x in [leaf for leaf in LevelGroupOrderIter(df_tree, filter_=lambda node: node.is_leaf and not node.is_root) if leaf])\n",
    "\n",
    "\n",
    "    # if metadata[metadata['File accession'] == file.replace('.bedpe', '')]['Experiment target'].iloc[0].replace('-human', '') == 'CTCF':\n",
    "    #     print('CTCF_interactions', len(df_tree.descendants))\n",
    "    #     print('CTCF_chains', sum(len(x) for x in [leaf for leaf in LevelGroupOrderIter(df_tree, filter_=lambda node: node.is_leaf and not node.is_root) if leaf]))\n",
    "    #     # for index, row in df.iterrows():\n",
    "    #     #     df.at[index, 'CTCF_interactions'] = row['CTCF_interactions'] + len(df_tree[index].descendants)\n",
    "    #     #     df.at[index, 'CTCF_chains'] = row['CTCF_chains'] + sum(len(x) for x in [leaf for leaf in LevelGroupOrderIter(df_tree[index], filter_=lambda node: node.is_leaf and not node.is_root) if leaf])\n",
    "    # else:\n",
    "    #     print('POLR2A_interactions', len(df_tree.descendants))\n",
    "    #     print('POLR2A_chains', sum(len(x) for x in [leaf for leaf in LevelGroupOrderIter(df_tree, filter_=lambda node: node.is_leaf and not node.is_root) if leaf]))\n",
    "        # for index, row in df.iterrows():\n",
    "        #     df.at[index, 'POLR2A_interactions'] = row['POLR2A_interactions'] + len(df_tree[index].descendants)\n",
    "        #     df.at[index, 'POLR2A_chains'] = row['POLR2A_chains'] + sum(len(x) for x in [leaf for leaf in LevelGroupOrderIter(df_tree[index], filter_=lambda node: node.is_leaf and not node.is_root) if leaf])      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('files_to_keep', 'wb') as f:\n",
    "    pickle.dump(files_to_keep, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(files_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = os.listdir(r\"C:/Users/Sana/Downloads/ChiaPET\")\n",
    "all_files.remove('files.txt')\n",
    "all_files.remove('metadata.tsv')\n",
    "all_files = [item for item in all_files if item in files_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_keep = [item + '.bedpe' for item in files_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([item for item in all_files if item in files_to_keep])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
