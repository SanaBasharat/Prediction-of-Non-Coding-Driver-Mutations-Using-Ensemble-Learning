{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import yaml\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss, accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn import preprocessing\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "with open(\"configuration.yaml\", \"r\") as yml_file:\n",
    "    config = yaml.load(yml_file, yaml.Loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/final_dataset.csv')\n",
    "\n",
    "for col in data.columns[data.isna().any()].tolist():\n",
    "    data[col].fillna(0, inplace=True)\n",
    "\n",
    "# data['TF_binding_site_agg'] = np.logical_or(data['TF_binding_site'], data['TF_binding_site_variant']).astype(int)\n",
    "\n",
    "# data['TF_loss_add'] = data['TF_binding_site_agg'] + data['TF_loss']\n",
    "# data['TF_gain_add'] = data['TF_binding_site_agg'] + data['TF_gain']\n",
    "# data['TF_loss_diff_add'] = data['TF_binding_site_agg'] + data['TF_loss_diff']\n",
    "# data['TF_gain_diff_add'] = data['TF_binding_site_agg'] + data['TF_gain_diff']\n",
    "\n",
    "data['SpliceAI_pred_DP_AG'] = abs(data['SpliceAI_pred_DP_AG'])\n",
    "data['SpliceAI_pred_DP_AL'] = abs(data['SpliceAI_pred_DP_AL'])\n",
    "data['SpliceAI_pred_DP_DG'] = abs(data['SpliceAI_pred_DP_DG'])\n",
    "data['SpliceAI_pred_DP_DL'] = abs(data['SpliceAI_pred_DP_DL'])\n",
    "\n",
    "\n",
    "data_test = data[(data['data_source'] == 'Rheinbay et al 2020') | (data['data_source'] == 'Dr.Nod 2023')]\n",
    "len_test_data = len(data_test)\n",
    "data_test = pd.concat([data_test, data[data['data_source'] == 'COSMIC'].sample(n=len_test_data)]).reset_index(drop=True)   # get an equal amount of negative data\n",
    "data = data.drop(data_test.index, inplace=False).reset_index(drop=True, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_PARAMS = {                                            # CODE SOURCE: containers_build\\boostdm\\config.py\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"reg_lambda\": 1,\n",
    "        \"random_state\": 42,\n",
    "        \"scale_pos_weight\": 1,\n",
    "        \"subsample\": 0.7,        # fraction of observations to be random samples for each tree\n",
    "        \"reg_alpha\": 0,          # L1 regularization term on weight\n",
    "        \"max_delta_step\": 0,    # positive value can help make the update step more conservative. generally not used\n",
    "        \"min_child_weight\": 1,\n",
    "        \"learning_rate\": 1e-03,\n",
    "        \"colsample_bylevel\": 1.0,\n",
    "        \"gamma\": 0,     # specifies the minimum loss reduction required to make a split. Makes the algorithm conservative\n",
    "        \"colsample_bytree\": 1.0,        # fraction of columns to be random samples for each tree\n",
    "        \"booster\": \"gbtree\",\n",
    "        \"max_depth\": 4, # Used to control over-fitting as higher depth will allow the model to learn relations very specific to a particular sample\n",
    "        \"silent\": 1,\n",
    "        \"seed\": 21,\n",
    "        # \"eval_metric\": 'logloss',\n",
    "        # \"early_stopping_rounds\": 2000\n",
    "        # \"reg_lambda\": 1,  # explore this further\n",
    "\n",
    "}\n",
    "\n",
    "COLUMNS_TRAINING = config['COLUMNS_TRAINING']\n",
    "\n",
    "BIASED_COLUMNS = ['chr', 'ref_x', 'IG_C_gene', 'IG_D_gene', 'IG_J_gene', 'IG_J_pseudogene']\n",
    "\n",
    "COLUMNS_TRAINING = [x for x in COLUMNS_TRAINING if x not in BIASED_COLUMNS]\n",
    "\n",
    "COLUMNS_SHAP = [f'my_shap_{x}' for x in COLUMNS_TRAINING]\n",
    "COLUMNS_TRAINING = COLUMNS_TRAINING[:10]\n",
    "\n",
    "for col in list(set(COLUMNS_TRAINING) - set(data.columns)):\n",
    "    data[col] = 0\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "data[COLUMNS_TRAINING] = min_max_scaler.fit_transform(data[COLUMNS_TRAINING])\n",
    "\n",
    "for col in list(set(COLUMNS_TRAINING) - set(data_test.columns)):\n",
    "    data_test[col] = 0\n",
    "\n",
    "data_test[COLUMNS_TRAINING] = min_max_scaler.fit_transform(data_test[COLUMNS_TRAINING])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data[COLUMNS_TRAINING], data['driver'],\n",
    "                                                    random_state=104, \n",
    "                                                    test_size=0.25, \n",
    "                                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:  1.2min finished\n",
      "Features: 1/10[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   9 out of   9 | elapsed:  1.2min finished\n",
      "Features: 2/10[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   8 out of   8 | elapsed:  1.5min finished\n",
      "Features: 3/10[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   7 out of   7 | elapsed:  1.3min finished\n",
      "Features: 4/10[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   6 out of   6 | elapsed:  1.1min finished\n",
      "Features: 5/10[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:   54.4s finished\n",
      "Features: 6/10[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:   41.5s remaining:   41.5s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   41.5s finished\n",
      "Features: 7/10[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:   38.1s finished\n",
      "Features: 8/10[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   32.3s finished\n",
      "Features: 10/10"
     ]
    }
   ],
   "source": [
    "params = XGB_PARAMS.copy()                                          \n",
    "params['n_estimators'] = 20000  # set it high enough to allow \"early stopping\" events below\n",
    "params['base_score'] = y_train.mean()\n",
    "params['silent'] = True\n",
    "# params['n_jobs'] = 1\n",
    "params['seed'] = 104\n",
    "model = XGBClassifier(**params)\n",
    "\n",
    "# Build step forward feature selection\n",
    "sfs1 = sfs(model,\n",
    "           k_features=(5, 10),\n",
    "           forward=True,\n",
    "           floating=False,\n",
    "           verbose=1,\n",
    "           scoring='accuracy',\n",
    "           cv=5,\n",
    "           n_jobs=4)\n",
    "\n",
    "sfs1 = sfs1.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "feat_cols = list(sfs1.k_feature_idx_)\n",
    "print(feat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ada_score</th>\n",
       "      <th>rf_score</th>\n",
       "      <th>ENSP</th>\n",
       "      <th>UNIPARC</th>\n",
       "      <th>GO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.351852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.114754</td>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.216049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.006173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.163934</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081967</td>\n",
       "      <td>0.104167</td>\n",
       "      <td>0.049383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.086420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.061728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.147541</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.952282</td>\n",
       "      <td>0.131148</td>\n",
       "      <td>0.104167</td>\n",
       "      <td>0.203704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>735 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ada_score  rf_score      ENSP   UNIPARC        GO\n",
       "297   0.000000  0.000000  0.016393  0.020833  0.351852\n",
       "179   0.000000  0.000000  0.114754  0.145833  0.216049\n",
       "554   0.000000  0.000000  0.016393  0.020833  0.006173\n",
       "583   0.000000  0.000000  0.163934  0.166667  0.055556\n",
       "137   0.000000  0.000000  0.081967  0.104167  0.049383\n",
       "..         ...       ...       ...       ...       ...\n",
       "654   0.000000  0.000000  0.098361  0.125000  0.086420\n",
       "251   0.000000  0.000000  0.016393  0.020833  0.611111\n",
       "729   0.000000  0.000000  0.016393  0.020833  0.061728\n",
       "705   0.000000  0.000000  0.147541  0.166667  0.166667\n",
       "69    0.999977  0.952282  0.131148  0.104167  0.203704\n",
       "\n",
       "[735 rows x 5 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.iloc[:, feat_cols]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
