{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import gzip\n",
    "from multiprocessing import Pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "import yaml\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "with open(\"configuration.yaml\", \"r\") as yml_file:\n",
    "    config = yaml.load(yml_file, yaml.Loader)\n",
    "\n",
    "COLUMNS_TRAINING = config['COLUMNS_TRAINING']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_filter(x_train, x_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Final preparation steps to achieve a competent CV data:\n",
    "    1) remove repeated data items in the test datasets\n",
    "       removing duplicate sites in test dataset --but not in training-- as repeated data in training provide us with\n",
    "       weight of evidence, whereas too many repeated data at testing can spoil our capacity to evaluate\n",
    "    2) random sampling to get a balanced test set\n",
    "    3) set training feature labels in a canonical order taken from configuration\n",
    "    \"\"\"\n",
    "\n",
    "    # reset index\n",
    "\n",
    "    x_test.reset_index(inplace=True, drop=True)\n",
    "    y_test.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    # remove duplicates from test set\n",
    "\n",
    "    x_test['chr'] = x_test['chr'].astype(str)\n",
    "    x_test['start'] = x_test['start'].astype(int)\n",
    "    x_test = x_test.drop_duplicates(['start', 'alt'])\n",
    "    test_index = x_test.index\n",
    "    y_test = y_test.loc[y_test.index.intersection(test_index)]\n",
    "\n",
    "    # balance test set\n",
    "\n",
    "    total_index = set(x_test.index)\n",
    "    if y_test.mean() <= 0.5:\n",
    "        balance_index = y_test[y_test == 1].index.tolist()\n",
    "    else:\n",
    "        balance_index = y_test[y_test == 0].index.tolist()\n",
    "    remaining_index = list(set(total_index) - set(balance_index))\n",
    "    balance_index += list(np.random.choice(remaining_index, size=len(balance_index), replace=False))\n",
    "    x_test = x_test.loc[x_test.index.intersection(balance_index)]\n",
    "    y_test = y_test.loc[y_test.index.intersection(balance_index)]\n",
    "\n",
    "    # feature labels in standard order\n",
    "    avoid = ['chr', 'start', 'ref', 'alt']\n",
    "    features = list(filter(lambda x: x not in avoid, x_train))\n",
    "    # print(set(features))\n",
    "    # assert (set(features) == set(COLUMNS_TRAINING))\n",
    "    x_train = x_train[avoid + COLUMNS_TRAINING]\n",
    "    x_test = x_test[avoid + COLUMNS_TRAINING]\n",
    "\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "def split_balanced(x_data, y_data, test_size=0.3):\n",
    "    \"\"\"Generate balanced train-test split\"\"\"\n",
    "\n",
    "    one_index  = list(y_data[y_data == 1].index)\n",
    "    zero_index = list(y_data[y_data == 0].index)\n",
    "\n",
    "    # randomly select n_ones indices from zero_index\n",
    "    zero_index = list(np.random.choice(zero_index, size=len(one_index), replace=False))\n",
    "\n",
    "    x_data_sub = x_data.loc[one_index + zero_index, :]\n",
    "    y_data_sub = y_data.loc[one_index + zero_index]\n",
    "\n",
    "    # the random state should be fixed prior to this call\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data_sub, y_data_sub, test_size=test_size)\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "def get_cv_sets_balanced(x_data, y_data, n, size):\n",
    "    \"\"\"Generate several balanced train-test sets\"\"\"\n",
    "\n",
    "    for _ in range(n):\n",
    "        x_train, x_test, y_train, y_test = split_balanced(x_data, y_data, test_size=size)\n",
    "        yield x_train, x_test, y_train, y_test\n",
    "\n",
    "def prepare(data, nsplits=10, test_size=0.2):\n",
    "\n",
    "    data.rename(columns={'response': 'label'}, inplace=True)\n",
    "\n",
    "    # keep 'pos' and 'chr' to run position-based filtering\n",
    "    avoid = ['cohort', 'gene', 'aachange', 'label', 'motif']  # include 'ref' 'alt'\n",
    "    features = list(filter(lambda x: x not in avoid, data.columns))\n",
    "\n",
    "    # regression datasets\n",
    "    x_data = data[features]\n",
    "    y_data = data['driver'] # label\n",
    "\n",
    "    # cv_list output has tuples (x_train, x_test, y_train, y_test) as elements\n",
    "    cv_list = get_cv_sets_balanced(x_data, y_data, nsplits, test_size)\n",
    "\n",
    "    # filter test data to prevent site repetitions\n",
    "    cv_list = [sort_filter(*arg) for arg in cv_list]\n",
    "\n",
    "    return cv_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mutations(input_path):\n",
    "\n",
    "    data = pd.read_csv(input_path, sep=',', low_memory=False)\n",
    "    return data\n",
    "\n",
    "def generate(mutations, random_state=None, bootstrap_splits=50, cv_fraction=0.3):\n",
    "\n",
    "    # fix random seed (if provided)\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    d_output = {}\n",
    "\n",
    "    # for gene, data in mutations.groupby('gene'):\n",
    "    cv_list = prepare(mutations.copy(), nsplits=bootstrap_splits, test_size=cv_fraction) # data.copy()\n",
    "    d_output = cv_list\n",
    "\n",
    "    return d_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/final_dataset.csv')\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "for col in data.columns[data.isna().any()].tolist():\n",
    "    data[col].fillna(0, inplace=True)\n",
    "\n",
    "data['TF_binding_site_agg'] = np.logical_or(data['TF_binding_site'], data['TF_binding_site_variant']).astype(int)\n",
    "\n",
    "data['TF_loss_add'] = data['TF_binding_site_agg'] + data['TF_loss']\n",
    "data['TF_gain_add'] = data['TF_binding_site_agg'] + data['TF_gain']\n",
    "data['TF_loss_diff_add'] = data['TF_binding_site_agg'] + data['TF_loss_diff']\n",
    "data['TF_gain_diff_add'] = data['TF_binding_site_agg'] + data['TF_gain_diff']\n",
    "\n",
    "data['SpliceAI_pred_DP_AG'] = abs(data['SpliceAI_pred_DP_AG'])\n",
    "data['SpliceAI_pred_DP_AL'] = abs(data['SpliceAI_pred_DP_AL'])\n",
    "data['SpliceAI_pred_DP_DG'] = abs(data['SpliceAI_pred_DP_DG'])\n",
    "data['SpliceAI_pred_DP_DL'] = abs(data['SpliceAI_pred_DP_DL'])\n",
    "\n",
    "\n",
    "data_test = data[(data['data_source'] == 'Rheinbay et al 2020') | (data['data_source'] == 'Dr.Nod 2023')]\n",
    "len_test_data = len(data_test)\n",
    "data_test = pd.concat([data_test, data[data['data_source'] == 'COSMIC'].sample(n=len_test_data)])   # get an equal amount of negative data\n",
    "data = data.drop(data_test.index, inplace=False).reset_index(drop=True, inplace=False)\n",
    "data_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mutations = load_mutations('data/final_dataset.csv')\n",
    "mutations = data.copy()\n",
    "\n",
    "mutations.drop(['chr_y', 'start_y', 'end_y'], inplace=True, axis=1)\n",
    "mutations.rename({'chr_x': 'chr', 'start_x': 'start', 'end_x': 'end'}, inplace=True, axis=1)\n",
    "\n",
    "d_output = generate(mutations,\n",
    "                    random_state=104,\n",
    "                    bootstrap_splits=50,\n",
    "                    cv_fraction=0.3)\n",
    "\n",
    "with gzip.open('data/splits.pkl', 'wb') as f:\n",
    "    pickle.dump(d_output, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mutations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_results = {\n",
    "        'models': [], 'split_number': [], 'x_test': [], 'y_test': [], 'learning_curves': []\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(values):\n",
    "    \"\"\"Returns: optimal classification threshold and trained XGB model\"\"\"\n",
    "    x_train, x_test, y_train, y_test, split_number, seed = tuple(values)\n",
    "    print(\"Train: \", split_number)\n",
    "    XGB_PARAMS = config['XGB_PARAMS']\n",
    "    params = XGB_PARAMS.copy()\n",
    "    params['n_estimators'] = 20000  # set it high enough to allow \"early stopping\" events below\n",
    "    params['base_score'] = y_train.mean()\n",
    "    # params['n_jobs'] = 1\n",
    "    params['seed'] = seed\n",
    "    myclassifier = XGBClassifier(**params)\n",
    "\n",
    "    # train with xgboost\n",
    "    learning_curve_dict = {}\n",
    "    myclassifier.fit(x_train, y_train,\n",
    "                       eval_set=[(x_train, y_train), (x_test, y_test)],\n",
    "                       callbacks=[\n",
    "                           xgboost.callback.EvaluationMonitor(rank=0, period=1, show_stdv=False),\n",
    "                       ],\n",
    "                       verbose=False)\n",
    "\n",
    "    params['n_estimators'] = myclassifier.model.best_iteration\n",
    "    learning_curve_dict = {k: v['logloss'][:params['n_estimators']] for k, v in learning_curve_dict.items()}\n",
    "    myclassifier.model.set_params(**params)\n",
    "\n",
    "    return myclassifier, split_number, x_test, y_test, learning_curve_dict\n",
    "\n",
    "file_cv = 'data/splits.pkl'\n",
    "min_rows = 30   # Minimum number of rows to carry out training\n",
    "non_features = ['start', 'chr', 'ref', 'alt']\n",
    "cores = 7\n",
    "with Pool(cores) as p:\n",
    "    with gzip.open(file_cv, 'rb') as f:\n",
    "        split_cv = pickle.load(f)\n",
    "\n",
    "    mean_size = np.nanmean([cv[0].shape[0] for cv in split_cv])\n",
    "    if mean_size < min_rows:\n",
    "        print(\"ERROR\")\n",
    "\n",
    "    list_cvs = []\n",
    "    for i, x in enumerate(split_cv):\n",
    "        print(\"Enumerate: \", i)\n",
    "        x_list = list(x) + [i, np.random.randint(100000)]\n",
    "\n",
    "        # filter out non-features, i.e., columns not used for training\n",
    "        x_list[0] = x_list[0].drop(non_features, axis=1)\n",
    "        x_list[1] = x_list[1].drop(non_features, axis=1)\n",
    "        list_cvs.append(x_list)\n",
    "\n",
    "    # for model, split_number, x_test, y_test, learning_curve in p.imap(\n",
    "    #         train, list_cvs):\n",
    "    #     print(\"Train: \", split_number)\n",
    "    #     dict_results['models'].append(model)\n",
    "    #     dict_results['split_number'].append(split_number)\n",
    "    #     dict_results['x_test'].append(x_test)\n",
    "    #     dict_results['y_test'].append(y_test)\n",
    "    #     dict_results['learning_curves'].append(learning_curve)\n",
    "\n",
    "    # with gzip.open('data/models.pkl', 'wb') as f:\n",
    "    #     pickle.dump(dict_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_cv = 'data/splits.pkl'\n",
    "min_rows = 30   # Minimum number of rows to carry out training\n",
    "non_features = ['start', 'chr', 'ref', 'alt']\n",
    "with gzip.open(file_cv, 'rb') as f:\n",
    "    split_cv = pickle.load(f)\n",
    "\n",
    "mean_size = np.nanmean([cv[0].shape[0] for cv in split_cv])\n",
    "if mean_size < min_rows:\n",
    "    print(\"ERROR\")\n",
    "\n",
    "list_cvs = []\n",
    "for i, x in enumerate(split_cv):\n",
    "    print(\"Enumerate: \", i)\n",
    "    x_list = list(x) + [i, np.random.randint(100000)]\n",
    "\n",
    "    # filter out non-features, i.e., columns not used for training\n",
    "    x_list[0] = x_list[0].drop(non_features, axis=1)\n",
    "    x_list[1] = x_list[1].drop(non_features, axis=1)\n",
    "    list_cvs.append(x_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12498]\tvalidation_0-logloss:0.10937\tvalidation_1-logloss:0.29899\n",
      "[12499]\tvalidation_0-logloss:0.10936\tvalidation_1-logloss:0.29898\n",
      "[12500]\tvalidation_0-logloss:0.10935\tvalidation_1-logloss:0.29898\n",
      "[12501]\tvalidation_0-logloss:0.10935\tvalidation_1-logloss:0.29897\n",
      "[12502]\tvalidation_0-logloss:0.10934\tvalidation_1-logloss:0.29897\n",
      "[12503]\tvalidation_0-logloss:0.10933\tvalidation_1-logloss:0.29897\n",
      "[12504]\tvalidation_0-logloss:0.10933\tvalidation_1-logloss:0.29897\n",
      "[12505]\tvalidation_0-logloss:0.10932\tvalidation_1-logloss:0.29897\n",
      "[12506]\tvalidation_0-logloss:0.10931\tvalidation_1-logloss:0.29898\n",
      "[12507]\tvalidation_0-logloss:0.10930\tvalidation_1-logloss:0.29898\n",
      "[12508]\tvalidation_0-logloss:0.10929\tvalidation_1-logloss:0.29898\n",
      "[12509]\tvalidation_0-logloss:0.10928\tvalidation_1-logloss:0.29898\n",
      "[12510]\tvalidation_0-logloss:0.10928\tvalidation_1-logloss:0.29898\n",
      "[12511]\tvalidation_0-logloss:0.10927\tvalidation_1-logloss:0.29898\n",
      "[12512]\tvalidation_0-logloss:0.10926\tvalidation_1-logloss:0.29899\n",
      "[12513]\tvalidation_0-logloss:0.10925\tvalidation_1-logloss:0.29900\n",
      "[12514]\tvalidation_0-logloss:0.10924\tvalidation_1-logloss:0.29899\n",
      "[12515]\tvalidation_0-logloss:0.10923\tvalidation_1-logloss:0.29899\n",
      "[12516]\tvalidation_0-logloss:0.10923\tvalidation_1-logloss:0.29899\n",
      "[12517]\tvalidation_0-logloss:0.10922\tvalidation_1-logloss:0.29899\n",
      "[12518]\tvalidation_0-logloss:0.10922\tvalidation_1-logloss:0.29899\n",
      "[12519]\tvalidation_0-logloss:0.10921\tvalidation_1-logloss:0.29900\n",
      "[12520]\tvalidation_0-logloss:0.10921\tvalidation_1-logloss:0.29898\n",
      "[12521]\tvalidation_0-logloss:0.10920\tvalidation_1-logloss:0.29897\n",
      "[12522]\tvalidation_0-logloss:0.10918\tvalidation_1-logloss:0.29896\n",
      "[12523]\tvalidation_0-logloss:0.10918\tvalidation_1-logloss:0.29895\n",
      "[12524]\tvalidation_0-logloss:0.10917\tvalidation_1-logloss:0.29894\n",
      "[12525]\tvalidation_0-logloss:0.10916\tvalidation_1-logloss:0.29894\n",
      "[12526]\tvalidation_0-logloss:0.10915\tvalidation_1-logloss:0.29894\n",
      "[12527]\tvalidation_0-logloss:0.10914\tvalidation_1-logloss:0.29894\n",
      "[12528]\tvalidation_0-logloss:0.10914\tvalidation_1-logloss:0.29895\n",
      "[12529]\tvalidation_0-logloss:0.10913\tvalidation_1-logloss:0.29895\n",
      "[12530]\tvalidation_0-logloss:0.10912\tvalidation_1-logloss:0.29896\n",
      "[12531]\tvalidation_0-logloss:0.10911\tvalidation_1-logloss:0.29897\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'XGBClassifier' object has no attribute 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m index \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(list_cvs)):\n\u001b[1;32m----> 2\u001b[0m     model, split_number, x_test, y_test, learning_curve \u001b[39m=\u001b[39m train(list_cvs[index])\n\u001b[0;32m      3\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTrain: \u001b[39m\u001b[39m\"\u001b[39m, split_number)\n\u001b[0;32m      4\u001b[0m     dict_results[\u001b[39m'\u001b[39m\u001b[39mmodels\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend(model)\n",
      "Cell \u001b[1;32mIn[1], line 22\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m     14\u001b[0m learning_curve_dict \u001b[39m=\u001b[39m {}\n\u001b[0;32m     15\u001b[0m myclassifier\u001b[39m.\u001b[39mfit(x_train, y_train,\n\u001b[0;32m     16\u001b[0m                    eval_set\u001b[39m=\u001b[39m[(x_train, y_train), (x_test, y_test)],\n\u001b[0;32m     17\u001b[0m                    callbacks\u001b[39m=\u001b[39m[\n\u001b[0;32m     18\u001b[0m                        xgboost\u001b[39m.\u001b[39mcallback\u001b[39m.\u001b[39mEvaluationMonitor(rank\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, period\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, show_stdv\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m),\n\u001b[0;32m     19\u001b[0m                    ],\n\u001b[0;32m     20\u001b[0m                    verbose\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m---> 22\u001b[0m params[\u001b[39m'\u001b[39m\u001b[39mn_estimators\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m myclassifier\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39mbest_iteration\n\u001b[0;32m     23\u001b[0m learning_curve_dict \u001b[39m=\u001b[39m {k: v[\u001b[39m'\u001b[39m\u001b[39mlogloss\u001b[39m\u001b[39m'\u001b[39m][:params[\u001b[39m'\u001b[39m\u001b[39mn_estimators\u001b[39m\u001b[39m'\u001b[39m]] \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m learning_curve_dict\u001b[39m.\u001b[39mitems()}\n\u001b[0;32m     24\u001b[0m myclassifier\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mset_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'XGBClassifier' object has no attribute 'model'"
     ]
    }
   ],
   "source": [
    "for index in range(0, len(list_cvs)):\n",
    "    model, split_number, x_test, y_test, learning_curve = train(list_cvs[index])\n",
    "    print(\"Train: \", split_number)\n",
    "    dict_results['models'].append(model)\n",
    "    dict_results['split_number'].append(split_number)\n",
    "    dict_results['x_test'].append(x_test)\n",
    "    dict_results['y_test'].append(y_test)\n",
    "    dict_results['learning_curves'].append(learning_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ensemble",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
