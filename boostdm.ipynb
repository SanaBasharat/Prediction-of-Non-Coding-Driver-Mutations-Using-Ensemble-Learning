{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sana\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "C:\\Users\\Sana\\AppData\\Local\\Temp\\ipykernel_29892\\1585305739.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import gzip\n",
    "from multiprocessing import Pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "import yaml\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "with open(\"configuration.yaml\", \"r\") as yml_file:\n",
    "    config = yaml.load(yml_file, yaml.Loader)\n",
    "\n",
    "COLUMNS_TRAINING = config['COLUMNS_TRAINING']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_filter(x_train, x_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Final preparation steps to achieve a competent CV data:\n",
    "    1) remove repeated data items in the test datasets\n",
    "       removing duplicate sites in test dataset --but not in training-- as repeated data in training provide us with\n",
    "       weight of evidence, whereas too many repeated data at testing can spoil our capacity to evaluate\n",
    "    2) random sampling to get a balanced test set\n",
    "    3) set training feature labels in a canonical order taken from configuration\n",
    "    \"\"\"\n",
    "\n",
    "    # reset index\n",
    "\n",
    "    x_test.reset_index(inplace=True, drop=True)\n",
    "    y_test.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    # remove duplicates from test set\n",
    "\n",
    "    x_test['chr'] = x_test['chr'].astype(str)\n",
    "    x_test['start'] = x_test['start'].astype(int)\n",
    "    x_test = x_test.drop_duplicates(['start', 'alt'])\n",
    "    test_index = x_test.index\n",
    "    y_test = y_test.loc[y_test.index.intersection(test_index)]\n",
    "\n",
    "    # balance test set\n",
    "\n",
    "    total_index = set(x_test.index)\n",
    "    if y_test.mean() <= 0.5:\n",
    "        balance_index = y_test[y_test == 1].index.tolist()\n",
    "    else:\n",
    "        balance_index = y_test[y_test == 0].index.tolist()\n",
    "    remaining_index = list(set(total_index) - set(balance_index))\n",
    "    balance_index += list(np.random.choice(remaining_index, size=len(balance_index), replace=False))\n",
    "    x_test = x_test.loc[x_test.index.intersection(balance_index)]\n",
    "    y_test = y_test.loc[y_test.index.intersection(balance_index)]\n",
    "\n",
    "    # feature labels in standard order\n",
    "    avoid = ['chr', 'start', 'ref', 'alt']\n",
    "    features = list(filter(lambda x: x not in avoid, x_train))\n",
    "    # print(set(features))\n",
    "    # assert (set(features) == set(COLUMNS_TRAINING))\n",
    "    x_train = x_train[avoid + COLUMNS_TRAINING]\n",
    "    x_test = x_test[avoid + COLUMNS_TRAINING]\n",
    "\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "def split_balanced(x_data, y_data, test_size=0.3):\n",
    "    \"\"\"Generate balanced train-test split\"\"\"\n",
    "\n",
    "    one_index  = list(y_data[y_data == 1].index)\n",
    "    zero_index = list(y_data[y_data == 0].index)\n",
    "\n",
    "    # randomly select n_ones indices from zero_index\n",
    "    zero_index = list(np.random.choice(zero_index, size=len(one_index), replace=False))\n",
    "\n",
    "    x_data_sub = x_data.loc[one_index + zero_index, :]\n",
    "    y_data_sub = y_data.loc[one_index + zero_index]\n",
    "\n",
    "    # the random state should be fixed prior to this call\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data_sub, y_data_sub, test_size=test_size)\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "def get_cv_sets_balanced(x_data, y_data, n, size):\n",
    "    \"\"\"Generate several balanced train-test sets\"\"\"\n",
    "\n",
    "    for _ in range(n):\n",
    "        x_train, x_test, y_train, y_test = split_balanced(x_data, y_data, test_size=size)\n",
    "        yield x_train, x_test, y_train, y_test\n",
    "\n",
    "def prepare(data, nsplits=10, test_size=0.2):\n",
    "\n",
    "    data.rename(columns={'response': 'label'}, inplace=True)\n",
    "\n",
    "    # keep 'pos' and 'chr' to run position-based filtering\n",
    "    avoid = ['cohort', 'gene', 'aachange', 'label', 'motif']  # include 'ref' 'alt'\n",
    "    features = list(filter(lambda x: x not in avoid, data.columns))\n",
    "\n",
    "    # regression datasets\n",
    "    x_data = data[features]\n",
    "    y_data = data['driver'] # label\n",
    "\n",
    "    # cv_list output has tuples (x_train, x_test, y_train, y_test) as elements\n",
    "    cv_list = get_cv_sets_balanced(x_data, y_data, nsplits, test_size)\n",
    "\n",
    "    # filter test data to prevent site repetitions\n",
    "    cv_list = [sort_filter(*arg) for arg in cv_list]\n",
    "\n",
    "    return cv_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mutations(input_path):\n",
    "\n",
    "    data = pd.read_csv(input_path, sep=',', low_memory=False)\n",
    "    return data\n",
    "\n",
    "def generate(mutations, random_state=None, bootstrap_splits=50, cv_fraction=0.3):\n",
    "\n",
    "    # fix random seed (if provided)\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    d_output = {}\n",
    "\n",
    "    # for gene, data in mutations.groupby('gene'):\n",
    "    cv_list = prepare(mutations.copy(), nsplits=bootstrap_splits, test_size=cv_fraction) # data.copy()\n",
    "    d_output = cv_list\n",
    "\n",
    "    return d_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutations = load_mutations('data/final_dataset.csv')\n",
    "\n",
    "mutations.drop(['chr_y', 'start_y', 'end_y'], inplace=True, axis=1)\n",
    "mutations.rename({'chr_x': 'chr', 'start_x': 'start', 'end_x': 'end'}, inplace=True, axis=1)\n",
    "\n",
    "# d_output = generate(mutations,\n",
    "#                     random_state=104,\n",
    "#                     bootstrap_splits=50,\n",
    "#                     cv_fraction=0.3)\n",
    "\n",
    "# with gzip.open('data/splits.pkl', 'wb') as f:\n",
    "#     pickle.dump(d_output, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_results = {\n",
    "        'models': [], 'split_number': [], 'x_test': [], 'y_test': [], 'learning_curves': []\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(values):\n",
    "    \"\"\"Returns: optimal classification threshold and trained XGB model\"\"\"\n",
    "\n",
    "    x_train, x_test, y_train, y_test, split_number, seed = tuple(values)\n",
    "    XGB_PARAMS = config['XGB_PARAMS']\n",
    "    params = XGB_PARAMS.copy()\n",
    "    params['n_estimators'] = 20000  # set it high enough to allow \"early stopping\" events below\n",
    "    params['base_score'] = y_train.mean()\n",
    "    params['n_jobs'] = 1\n",
    "    params['seed'] = seed\n",
    "    myclassifier = XGBClassifier(**params)\n",
    "\n",
    "    # train with xgboost\n",
    "    learning_curve_dict = {}\n",
    "    myclassifier.train(x_train, y_train,\n",
    "                       eval_set=[(x_train, y_train), (x_test, y_test)],\n",
    "                       eval_metric='logloss',  # mcc_loss could be used here\n",
    "                       early_stopping_rounds=2000,\n",
    "                       callbacks=[\n",
    "                           xgboost.callback.EvaluationMonitor(rank=0, period=1, show_stdv=False),\n",
    "                       ],\n",
    "                       verbose=False)\n",
    "\n",
    "    params['n_estimators'] = myclassifier.model.best_iteration\n",
    "    learning_curve_dict = {k: v['logloss'][:params['n_estimators']] for k, v in learning_curve_dict.items()}\n",
    "    myclassifier.model.set_params(**params)\n",
    "\n",
    "    return myclassifier, split_number, x_test, y_test, learning_curve_dict\n",
    "\n",
    "file_cv = 'data/splits.pkl'\n",
    "min_rows = 30   # Minimum number of rows to carry out training\n",
    "non_features = ['start', 'chr', 'ref', 'alt']\n",
    "cores = 1\n",
    "with Pool(cores) as p:\n",
    "    with gzip.open(file_cv, 'rb') as f:\n",
    "        split_cv = pickle.load(f)\n",
    "\n",
    "    mean_size = np.nanmean([cv[0].shape[0] for cv in split_cv])\n",
    "    if mean_size < min_rows:\n",
    "        print(\"ERROR\")\n",
    "\n",
    "    list_cvs = []\n",
    "    for i, x in enumerate(split_cv):\n",
    "        x_list = list(x) + [i, np.random.randint(100000)]\n",
    "\n",
    "        # filter out non-features, i.e., columns not used for training\n",
    "        x_list[0] = x_list[0].drop(non_features, axis=1)\n",
    "        x_list[1] = x_list[1].drop(non_features, axis=1)\n",
    "        list_cvs.append(x_list)\n",
    "\n",
    "    for model, split_number, x_test, y_test, learning_curve in p.imap(\n",
    "            train, list_cvs):\n",
    "        dict_results['models'].append(model)\n",
    "        dict_results['split_number'].append(split_number)\n",
    "        dict_results['x_test'].append(x_test)\n",
    "        dict_results['y_test'].append(y_test)\n",
    "        dict_results['learning_curves'].append(learning_curve)\n",
    "\n",
    "    with gzip.open('data/models.pkl', 'wb') as f:\n",
    "        pickle.dump(dict_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "COLUMNS_SHAP = [f'my_shap_{x}' for x in COLUMNS_TRAINING]\n",
    "def predict(mutations, ttype, models, models_folder, evaluations_folder):\n",
    "\n",
    "    # hierarchy = Hierarchy(models)\n",
    "\n",
    "    # print(ttype)\n",
    "    # print(mutations['gene'].unique())\n",
    "    # get_model = functools.partial(hierarchy.get_model_for_gene, ttype=ttype)\n",
    "    get_model = models\n",
    "    d = dict(map(get_model, mutations['gene'].unique()))\n",
    "    mutations['selected_model_ttype'], mutations['selected_model_gene'] = zip(*mutations['gene'].map(d))\n",
    "\n",
    "    return _predict(mutations, models_folder, evaluations_folder)\n",
    "\n",
    "def _predict(mutations, models_folder, evaluations_folder):\n",
    "\n",
    "    # Prepare space for the columns\n",
    "    for c in COLUMNS_SHAP:\n",
    "        mutations[c] = np.nan\n",
    "    mutations['boostDM_score'] = np.nan\n",
    "\n",
    "    for name, df in mutations.groupby(['selected_model_gene', 'selected_model_ttype']):\n",
    "        gene, ttype = name\n",
    "        print(gene, ttype)\n",
    "        if gene is None:\n",
    "            return\n",
    "        else:\n",
    "            path_model = os.path.join(models_folder, f'{ttype}', f'{gene}.models.pickle.gz')\n",
    "            with gzip.open(path_model, 'rb') as f:\n",
    "                model = pickle.load(f)\n",
    "\n",
    "            path_eval = os.path.join(evaluations_folder, f'{ttype}', f'{gene}.eval.pickle.gz')\n",
    "            with gzip.open(path_eval, 'rb') as g:\n",
    "                evaluation = pickle.load(g)\n",
    "\n",
    "            mutations.loc[df.index, ['boostDM_score']] = bootstrap_voting(model, evaluation)(df[COLUMNS_TRAINING])\n",
    "\n",
    "            # SHAP attribution\n",
    "            x_data = df[COLUMNS_TRAINING]\n",
    "\n",
    "            shap_bootstrap = []\n",
    "            for model in model['models']:\n",
    "                explainer = shap.TreeExplainer(model.model)\n",
    "                shap_bootstrap.append(explainer.shap_values(x_data))\n",
    "            shap_values = np.mean(shap_bootstrap, axis=0)\n",
    "\n",
    "            mutations.loc[df.index, COLUMNS_SHAP] = shap_values\n",
    "\n",
    "    mutations.loc[:, 'boostDM_class'] = mutations['boostDM_score'].apply(lambda x: x >= 0.5)\n",
    "    return mutations\n",
    "\n",
    "def bootstrap_voting(model_obj, eval_obj, use_weights=True):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        model_obj: instance of model for a specific ttype-gene\n",
    "        eval_obj: evaluation instance for the same specific ttype-gene\n",
    "        use_weights\n",
    "    Return:\n",
    "        function: that given a vector of features, it returns a prediction label and score\n",
    "                  based on individual predictions and voting among all models and thresholds\n",
    "        warning:  at this point probabilities may need a final recalibration step\n",
    "    Satopaa, V. A. et al. Combining multiple probability predictions using a simple logit model.\n",
    "    International Journal of Forecasting 30, 344–356 (2014).\n",
    "    \"\"\"\n",
    "\n",
    "    models = model_obj['models']\n",
    "    logloss = eval_obj['logloss']\n",
    "\n",
    "    # estimate overall systematic bias\n",
    "    weights = 1 / np.array(logloss)\n",
    "    weights = weights / np.sum(weights)\n",
    "    bias = 2.3  # estimate of systematic bias based on testing with BRCA TCGA data\n",
    "\n",
    "    def func(x):\n",
    "\n",
    "        prod = 1\n",
    "        for i, model in enumerate(models):\n",
    "            feature_names = model.model.get_booster().feature_names\n",
    "            p = model.predict_proba(x[feature_names])[:, 1]\n",
    "            if use_weights:\n",
    "                prod *= (p / (1 - p)) ** weights[i]  # weighting based on logloss\n",
    "            else:\n",
    "                prod *= (p / (1 - p)) ** (1 / len(weights))  # otherwise, balanced weighting\n",
    "        prod = prod ** bias  # correction for systematic bias\n",
    "        s = (prod / (1 + prod))\n",
    "\n",
    "        return s\n",
    "\n",
    "    return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(model_selection, 'rb') as g:\n",
    "    models = pickle.load(g)\n",
    "df = predict(df_mutations, ttype=tumor_type, models=models, models_folder=models_folder, evaluations_folder=evaluations_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ensemble",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
